{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "def create_simclr_transforms(img_size, mean, std):\n",
    "    \"\"\"Creates train and test transforms for SimCLR data augmentation.\n",
    "\n",
    "    Args:\n",
    "        img_size (int): Desired image size after transformations.\n",
    "        mean (tuple): Mean values for normalization (e.g., CIFAR-10: (0.4914, 0.4822, 0.4465)).\n",
    "        std (tuple): Standard deviation values for normalization (e.g., CIFAR-10: (0.2023, 0.1994, 0.2010)).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_transform, test_transform)\n",
    "    \"\"\"\n",
    "\n",
    "    # Augmentations for both views (consider adding more as needed)\n",
    "    common_transforms = [\n",
    "        transforms.RandomResizedCrop(img_size),  # Resize with aspect ratio preservation\n",
    "        transforms.RandomHorizontalFlip(),      # Random horizontal flip\n",
    "        transforms.RandomGrayscale(p=0.2),    # Randomly convert to grayscale\n",
    "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),  # Color jitter\n",
    "        transforms.RandomRotation(degrees=15),   # Random rotations\n",
    "        transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),  # Random affine transformations\n",
    "        transforms.GaussianBlur(kernel_size=int(0.1 * img_size), sigma=(0.01, 0.02)),  # Gaussian blur\n",
    "    ]\n",
    "    # Train-specific augmentations (introduce more diversity here)\n",
    "    train_transforms = common_transforms + [\n",
    "        transforms.RandomCrop(img_size, padding=4),\n",
    "        transforms.ToTensor()  # Random cropping with padding\n",
    "    ]\n",
    "\n",
    "    # Test transforms (no data augmentation, only normalization)\n",
    "    test_transforms = [\n",
    "        transforms.Resize(img_size),  # Resize while maintaining aspect ratio\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ]\n",
    "\n",
    "    train_transform = transforms.Compose(train_transforms)\n",
    "    test_transform = transforms.Compose(test_transforms)\n",
    "\n",
    "    return train_transform, test_transform\n",
    "\n",
    "# Specify image size and normalization parameters for your dataset\n",
    "img_size = 32  # Example for CIFAR-10\n",
    "mean = (0.4914, 0.4822, 0.4465)  # Example for CIFAR-10\n",
    "std = (0.2023, 0.1994, 0.2010)  # Example for CIFAR-10\n",
    "\n",
    "train_transform, test_transform = create_simclr_transforms(img_size, mean, std)\n",
    "\n",
    "# Load CIFAR-10 dataset with the created transforms\n",
    "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "# Create DataLoaders with appropriate parameters\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "def create_simclr_model(pretrained=True, input_shape=(3, 32, 32)):\n",
    "    \"\"\"Creates a SimCLR model with a frozen ResNet-18 base and a specific projection head.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool, optional): Whether to use pretrained weights. Defaults to True.\n",
    "        input_shape (tuple, optional): Input image shape (channels, height, width). Defaults to (3, 32, 32).\n",
    "\n",
    "    Returns:\n",
    "        torch.nn.Module: The SimCLR model.\n",
    "    \"\"\"\n",
    "\n",
    "    model = resnet18(pretrained=pretrained)\n",
    "\n",
    "    # Freeze all ResNet layers except the final layer\n",
    "    for name, param in model.named_parameters():\n",
    "        if not name.startswith(\"fc.\"):\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Define the desired projection head with ReLU non-linearities\n",
    "    projection_head = torch.nn.Sequential(\n",
    "        torch.nn.Linear(model.fc.in_features, 128),\n",
    "        torch.nn.ReLU(inplace=True),\n",
    "        torch.nn.Linear(128, 32),\n",
    "        torch.nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "    # Replace the final layer with the projection head\n",
    "    model.fc = projection_head\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def nt_xent_loss(z1, z2, temperature=0.5):\n",
    "    \"\"\"Implements the Normalized Cross-Entropy (NCE) loss for SimCLR.\n",
    "\n",
    "    Args:\n",
    "        z1 (torch.Tensor): Features of positive views (shape: batch_size, feature_dim).\n",
    "        z2 (torch.Tensor): Features of negative views (shape: batch_size, feature_dim).\n",
    "        temperature (float, optional): Temperature parameter for normalization (default: 0.5).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Mean NCE loss.\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalize representations\n",
    "    z1_norm = F.normalize(z1, dim=1)\n",
    "    z2_norm = F.normalize(z2, dim=1)\n",
    "\n",
    "    # Calculate pairwise similarities\n",
    "    logits = torch.einsum(\"bi,bj->bij\", z1_norm, z2_norm.T) / temperature\n",
    "\n",
    "    # Generate ground-truth labels for positive pairs\n",
    "    batch_size = z1.shape[0]\n",
    "    labels = torch.arange(batch_size).long().to(z1.device)\n",
    "\n",
    "    # Compute NCE loss and return mean\n",
    "    loss = F.cross_entropy(logits, labels, reduction='mean')\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sairam/anaconda3/envs/assignment/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/sairam/anaconda3/envs/assignment/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "model = resnet18(pretrained=True)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)  # AdamW with weight decay\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=len(trainloader), eta_min=0.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "device = \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "def train_simclr(model, trainloader, optimizer, scheduler, device, nt_xent_loss, epochs=100):\n",
    "    \"\"\"Trains a SimCLR model with the given parameters.\n",
    "\n",
    "    Args:\n",
    "        model: The SimCLR model.\n",
    "        trainloader: The training data loader.\n",
    "        optimizer: The optimizer (e.g., AdamW).\n",
    "        scheduler: The learning rate scheduler (e.g., CosineAnnealingLR).\n",
    "        device: The device to use (e.g., 'cuda' or 'cpu').\n",
    "        nt_xent_loss: The NCE loss function.\n",
    "        epochs: Number of training epochs (default: 100).\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    device = \"cpu\"\n",
    "    transform = create_simclr_transforms(img_size, mean, std) \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "        for i, (images, targets) in enumerate(trainloader):\n",
    "            # Move data to device\n",
    "            images = images.to(device)\n",
    "        # for i, (images, targets) in enumerate(trainloader):\n",
    "        #     print(i, images.shape, targets.shape)\n",
    "        #     break  # Only print one batch\n",
    "\n",
    "\n",
    "            # Data augmentation for contrastive learning\n",
    "        with torch.no_grad():\n",
    "            augmented_images = transform(images)\n",
    "\n",
    "            # Concatenate original and augmented images\n",
    "            inputs = torch.cat([images, augmented_images], dim=0)\n",
    "\n",
    "            # Forward pass and embedding extraction\n",
    "            embeddings = model(inputs)\n",
    "\n",
    "            # Calculate NT-Xent loss\n",
    "            pos_embeddings = embeddings[:images.size(0)]  # Positive views\n",
    "            neg_embeddings = embeddings[images.size(0):]  # Negative views\n",
    "            loss = nt_xent_loss(pos_embeddings, neg_embeddings)\n",
    "\n",
    "            # Backpropagation and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update learning rate (if using scheduler)\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "            # Optional progress logging\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Batch {i}/{len(trainloader)} - Loss: {loss.item()}\")\n",
    "\n",
    "        # Additional epoch-level logging or evaluation (optional)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ... (your model, data loader, optimizer, scheduler, device, and data_augmentation setup)\n",
    "    train_simclr(model, trainloader, optimizer, scheduler, device, nt_xent_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "\n",
    "# Sample images from your dataset\n",
    "num_images = 5\n",
    "\n",
    "# Data preprocessing and augmentation for visualization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),  # Adjust size as needed\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # Adjust for your dataset\n",
    "])\n",
    "\n",
    "images = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "sample_idx = torch.randint(len(images), size=(num_images,))\n",
    "sample_images = images[sample_idx]\n",
    "\n",
    "# Define augmentations to visualize\n",
    "augmentations = [\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop(224),  # Adjust size as needed\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.GaussianBlur(kernel_size=3, sigma=0.5),\n",
    "]\n",
    "\n",
    "# Apply augmentations and create plot\n",
    "fig, axes = plt.subplots(nrows=num_images, ncols=len(augmentations) + 1, figsize=(12, 12))\n",
    "\n",
    "for i, image in enumerate(sample_images):\n",
    "    ax = axes[i, 0]\n",
    "    ax.imshow(image.permute(1, 2, 0))  # Convert from CxHxW to HxWxC\n",
    "    ax.set_title(f\"Original Image {i + 1}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "    for j, aug in enumerate(augmentations):\n",
    "        augmented_image = aug(image.clone())\n",
    "        ax = axes[i, j + 1]\n",
    "        ax.imshow(augmented_image.permute(1, 2, 0))\n",
    "        ax.set_title(f\"Augmentation {j + 1}\")\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
